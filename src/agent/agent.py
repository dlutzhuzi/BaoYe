import os
import json
import base64
import tempfile
import asyncio
from typing import Dict, List, Optional, Any, Tuple, Set, Literal
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.graph.state import CompiledStateGraph
from PIL import Image
import requests
from dotenv import load_dotenv
import chainlit as cl

# ===================== çŠ¶æ€æ¨¡å‹ =====================
class NodeHistory(BaseModel):
    """èŠ‚ç‚¹å†å²è®°å½•"""
    node_name: str = Field(description="èŠ‚ç‚¹åç§°")
    node_result: str = Field(description="èŠ‚ç‚¹è¿”å›ç»“æœ")
    
class SingleImageState(BaseModel):
    """å•å¼ å›¾ç‰‡çš„éå†çŠ¶æ€"""
    image_idx: int = Field(description="å›¾ç‰‡ç´¢å¼•ï¼ˆ0-basedï¼‰")
    current_node: str = Field(default="root", description="å½“å‰æ£€æŸ¥èŠ‚ç‚¹")
    node_result: str = Field(default="", description="å½“å‰èŠ‚ç‚¹APIè¿”å›ç»“æœ")
    pending_nodes: List[str] = Field(default_factory=list, description="å¾…æ£€æŸ¥èŠ‚ç‚¹é˜Ÿåˆ—")
    visited_nodes: Set[str] = Field(default_factory=set, description="å·²è®¿é—®èŠ‚ç‚¹ï¼ˆé˜²é‡å…¥ï¼‰")
    risks: List[str] = Field(default_factory=list, description="æ”¶é›†çš„é£é™©é¡¹")
    rectifies: List[str] = Field(default_factory=list, description="æ”¶é›†çš„æ•´æ”¹å»ºè®®")
    is_finished: bool = Field(default=False, description="æœ¬å›¾ç‰‡æ£€æŸ¥æ˜¯å¦å®Œæˆ")
    node_history: List[NodeHistory] = Field(default_factory=list, description="èŠ‚ç‚¹å†å²è®°å½•")

class MultiImageState(BaseModel):
    """å¤šå¼ å›¾ç‰‡çš„å…¨å±€çŠ¶æ€"""
    all_images_base64: List[str] = Field(description="æ‰€æœ‰å›¾ç‰‡çš„Base64")
    tree_config: Dict[str, Any] = Field(description="æ ‘å½¢æ£€æŸ¥é…ç½®")
    
    # æ¯å¼ å›¾ç‰‡çš„ç‹¬ç«‹çŠ¶æ€
    image_states: Dict[int, SingleImageState] = Field(default_factory=dict)
    
    # å…¨å±€è¿›åº¦æ§åˆ¶
    completed_images: Set[int] = Field(default_factory=set, description="å·²å®Œæˆçš„å›¾ç‰‡")
    total_images: int = Field(description="å›¾ç‰‡æ€»æ•°")
    
    # æœ€ç»ˆèšåˆç»“æœ
    final_results: Dict[int, Dict[str, List[str]]] = Field(default_factory=lambda: {
        # ç»“æ„ï¼š{å›¾ç‰‡ç¼–å·: {"risk": [], "rectify": []}}
    })

# ===================== å·¥å…·å‡½æ•° =====================
load_dotenv()
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
if not DASHSCOPE_API_KEY:
    raise ValueError("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®DASHSCOPE_API_KEY")

DASHSCOPE_API_URL = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation"

def image_to_base64_with_prefix(image_path: str) -> str:
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨ï¼š{image_path}")
    try:
        with Image.open(image_path) as img:
            img_format = img.format.lower()
            if img_format == "jpg":
                img_format = "jpeg"
            if img_format not in ["jpeg", "png"]:
                raise ValueError(f"âŒ ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼š{img.format}ï¼Œä»…æ”¯æŒJPG/PNG")
    except Exception as e:
        raise ValueError(f"âŒ è¯†åˆ«å›¾ç‰‡æ ¼å¼å¤±è´¥ï¼š{str(e)}")
    with open(image_path, "rb") as f:
        base64_str = base64.b64encode(f.read()).decode("utf-8").strip()
    return f"data:image/{img_format};base64,{base64_str}"

def call_qwen_vl_api(image_base64: str, prompt: str) -> str:
    headers = {
        "Authorization": f"Bearer {DASHSCOPE_API_KEY}",
        "Content-Type": "application/json"
    }
    content = [
        {"type": "image", "image": image_base64},
        {"type": "text", "text": prompt}
    ]
    payload = {
        "model": "qwen3-vl-plus",
        "input": {"messages": [{"role": "user", "content": content}]},
        "parameters": {"temperature": 0.1, "result_format": "message"}
    }
    try:
        response = requests.post(DASHSCOPE_API_URL, headers=headers, json=payload, timeout=60)
        response_json = response.json()
        response.raise_for_status()
        choices = response_json["output"]["choices"]
        if not choices:
            raise RuntimeError("âŒ æ— æœ‰æ•ˆå›å¤")
        content_list = choices[0]["message"]["content"]
        pure_text = content_list[0]["text"] if (isinstance(content_list, list) and len(content_list) > 0) else str(content_list)
        return pure_text.strip()
    except Exception as e:
        raise RuntimeError(f"âŒ APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}")

# ===================== å¤šå›¾ç‰‡APIè°ƒç”¨å‡½æ•° =====================
def call_qwen_vl_with_multiple_images(image_base64_list: List[str], prompt: str) -> str:
    """è°ƒç”¨Qwen-VL APIå¤„ç†å¤šå¼ å›¾ç‰‡"""
    headers = {
        "Authorization": f"Bearer {DASHSCOPE_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # æ„å»ºåŒ…å«æ‰€æœ‰å›¾ç‰‡çš„content
    content = []
    
    # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
    for idx, img_base64 in enumerate(image_base64_list):
        content.append({"type": "image", "image": img_base64})
        # æ·»åŠ å›¾ç‰‡ç¼–å·æç¤ºï¼ˆå¯é€‰ï¼Œå¸®åŠ©æ¨¡å‹åŒºåˆ†å›¾ç‰‡ï¼‰
        # content.append({"type": "text", "text": f"å›¾ç‰‡{idx+1}ï¼š"})
    
    # æ·»åŠ æ–‡æœ¬æç¤º
    content.append({"type": "text", "text": prompt})
    
    payload = {
        "model": "qwen3-vl-plus",
        "input": {"messages": [{"role": "user", "content": content}]},
        "parameters": {"temperature": 0.1, "result_format": "message"}
    }
    
    try:
        response = requests.post(DASHSCOPE_API_URL, headers=headers, json=payload, timeout=90)
        response_json = response.json()
        response.raise_for_status()
        choices = response_json["output"]["choices"]
        if not choices:
            raise RuntimeError("âŒ æ— æœ‰æ•ˆå›å¤")
        content_list = choices[0]["message"]["content"]
        pure_text = content_list[0]["text"] if (isinstance(content_list, list) and len(content_list) > 0) else str(content_list)
        return pure_text.strip()
    except Exception as e:
        raise RuntimeError(f"âŒ å¤šå›¾ç‰‡APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}")

# ===================== æ™ºèƒ½ä¸Šä¸‹æ–‡æ„å»ºå™¨ =====================
class ContextBuilder:
    """æ ¹æ®é…ç½®æ™ºèƒ½æ„å»ºä¸Šä¸‹æ–‡"""
    
    @staticmethod
    def build_context(node_history: List[NodeHistory], context_type: str = "none", current_node: str = "") -> str:
        """
        æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        
        Args:
            node_history: èŠ‚ç‚¹å†å²è®°å½•
            context_type: ä¸Šä¸‹æ–‡ç±»å‹ - none/parent/all
            current_node: å½“å‰èŠ‚ç‚¹åç§°
        
        Returns:
            ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if context_type == "none" or not node_history:
            return ""
        
        if context_type == "parent":
            # åªè·å–çˆ¶èŠ‚ç‚¹ä¿¡æ¯
            if len(node_history) > 0:
                parent = node_history[-1]  # æœ€åä¸€ä¸ªå°±æ˜¯çˆ¶èŠ‚ç‚¹
                return f"ğŸ“‹ çˆ¶èŠ‚ç‚¹æ£€æŸ¥ç»“æœï¼š\n{parent.node_name}: {parent.node_result}\n\n"
            return ""
        
        elif context_type == "all":
            # è·å–æ‰€æœ‰å†å²ä¿¡æ¯ï¼ˆé™¤äº†å½“å‰èŠ‚ç‚¹ï¼‰
            if not node_history:
                return ""
            
            context_lines = ["ğŸ“‹ æ£€æŸ¥å†å²è®°å½•ï¼š"]
            for i, history in enumerate(node_history):
                if history.node_result:
                    # ç¾åŒ–æ˜¾ç¤º
                    display_name = history.node_name
                    display_result = history.node_result
                    
                    # ç‰¹æ®Šå¤„ç†æ ¹èŠ‚ç‚¹
                    if history.node_name == "root":
                        display_name = "åˆå§‹æ£€æŸ¥"
                        if display_result and display_result != "æ— ":
                            display_result = f"å‘ç°ï¼š{display_result}"
                    
                    context_lines.append(f"{i+1}. {display_name}: {display_result}")
            
            if len(context_lines) > 1:
                return "\n".join(context_lines) + "\n\n"
        
        return ""
    
    @staticmethod
    def build_enhanced_prompt(
        node_history: List[NodeHistory],
        base_prompt: str,
        node_name: str,
        context_type: str = "none"
    ) -> str:
        """
        æ„å»ºå¢å¼ºçš„prompt
        
        Args:
            node_history: èŠ‚ç‚¹å†å²
            base_prompt: åŸºç¡€prompt
            node_name: å½“å‰èŠ‚ç‚¹åç§°
            context_type: ä¸Šä¸‹æ–‡ç±»å‹
        
        Returns:
            å¢å¼ºçš„prompt
        """
        # æ„å»ºä¸Šä¸‹æ–‡
        context = ContextBuilder.build_context(node_history, context_type, node_name)
        
        if not context:
            return base_prompt
        
        # æ ¹æ®èŠ‚ç‚¹ç±»å‹æ·»åŠ æŒ‡å¯¼è¯­
        guidance = ""
        
        # æ£€æŸ¥èŠ‚ç‚¹åç§°ï¼Œæ·»åŠ ç‰¹å®šæŒ‡å¯¼
        if "cable" in node_name.lower():
            guidance = "\næ³¨æ„ï¼šè¯·åŸºäºä¹‹å‰çš„ç”µç¼†æ£€æŸ¥ç»“æœè¿›è¡Œåˆ¤æ–­ã€‚"
        elif "box" in node_name.lower() or "é…ç”µ" in node_name.lower():
            guidance = "\næ³¨æ„ï¼šè¯·åŸºäºé…ç”µç®±çš„æ£€æŸ¥æƒ…å†µè¿›è¡Œç»¼åˆè¯„ä¼°ã€‚"
        
        # æ„å»ºæœ€ç»ˆprompt
        enhanced_prompt = f"""{context}æ ¹æ®ä»¥ä¸Šæ£€æŸ¥å†å²ï¼Œç°åœ¨éœ€è¦è¿›è¡Œä¸‹ä¸€æ­¥æ£€æŸ¥ã€‚

{base_prompt}{guidance}

è¯·ç»“åˆå†å²æ£€æŸ¥ç»“æœï¼Œç»™å‡ºå‡†ç¡®çš„åˆ¤æ–­ã€‚"""
        
        return enhanced_prompt

# ===================== æ ¸å¿ƒèŠ‚ç‚¹ =====================
def process_image_node(state: MultiImageState) -> Dict:
    """å¤„ç†å•å¼ å›¾ç‰‡çš„å½“å‰èŠ‚ç‚¹"""
    # åˆ›å»ºæ–°çš„çŠ¶æ€å¯¹è±¡
    new_state = MultiImageState(
        all_images_base64=state.all_images_base64.copy(),
        tree_config=state.tree_config.copy(),
        image_states={k: SingleImageState(**v.dict()) for k, v in state.image_states.items()},
        completed_images=state.completed_images.copy(),
        total_images=state.total_images,
        final_results=state.final_results.copy()
    )
    
    # æ‰¾å‡ºéœ€è¦å¤„ç†çš„å›¾ç‰‡
    active_images = [
        idx for idx, img_state in new_state.image_states.items()
        if not img_state.is_finished and idx not in new_state.completed_images
    ]
    
    if not active_images:
        aggregate_results(new_state)
        return new_state.dict()
    
    # å¤„ç†ç¬¬ä¸€å¼ æ´»è·ƒå›¾ç‰‡
    current_idx = active_images[0]
    img_state = new_state.image_states[current_idx]
    
    print(f"ğŸ”„ å¤„ç†å›¾ç‰‡{current_idx+1} - å½“å‰èŠ‚ç‚¹ï¼š{img_state.current_node}")
    
    # æ£€æŸ¥æ˜¯å¦å·²è®¿é—®è¿‡è¯¥èŠ‚ç‚¹
    if img_state.current_node in img_state.visited_nodes:
        print(f"âš ï¸  å›¾ç‰‡{current_idx+1}èŠ‚ç‚¹{img_state.current_node}å·²è®¿é—®ï¼Œè·³è¿‡")
        if img_state.pending_nodes:
            img_state.current_node = img_state.pending_nodes.pop(0)
        else:
            img_state.is_finished = True
            new_state.completed_images.add(current_idx)
        return new_state.dict()
    
    img_state.visited_nodes.add(img_state.current_node)
    
    # è·å–èŠ‚ç‚¹é…ç½®
    image_base64 = new_state.all_images_base64[current_idx]
    node_config = new_state.tree_config.get(img_state.current_node, {})
    
    # è®°å½•å½“å‰èŠ‚ç‚¹åˆ°å†å²ï¼ˆåœ¨æ‰§è¡Œå‰è®°å½•ï¼‰
    current_history = NodeHistory(
        node_name=img_state.current_node,
        node_result=""  # åˆå§‹ä¸ºç©º
    )
    img_state.node_history.append(current_history)
    
    # è·å–ä¸Šä¸‹æ–‡ç±»å‹é…ç½®ï¼ˆé»˜è®¤ä¸º"none"ï¼‰
    context_type = node_config.get("context", "none")
    print(f"ğŸ“ èŠ‚ç‚¹{img_state.current_node}çš„ä¸Šä¸‹æ–‡ç±»å‹ï¼š{context_type}")
    
    # å¤„ç†æ ¹èŠ‚ç‚¹
    if img_state.current_node == "root":
        prompt = node_config.get("prompt", "")
        if prompt:
            result = call_qwen_vl_api(image_base64, prompt)
            img_state.node_result = result
            current_history.node_result = result
            
            print(f"ğŸ“Œ å›¾ç‰‡{current_idx+1} rootèŠ‚ç‚¹è¿”å›ï¼š{result}")
            
            # è§£æè¿”å›çš„å…ƒç´ 
            elements = [
                elem.strip() for elem in result.split(",") 
                if elem.strip() and elem.strip() != "æ— "
            ]
            
            # æ˜ å°„åˆ°å­èŠ‚ç‚¹
            child_map = node_config.get("child_map", {})
            for element in elements:
                next_node = child_map.get(element)
                if next_node and next_node not in img_state.visited_nodes:
                    img_state.pending_nodes.append(next_node)
            
            print(f"ğŸ“Œ å›¾ç‰‡{current_idx+1} ç”Ÿæˆå¾…å¤„ç†èŠ‚ç‚¹ï¼š{img_state.pending_nodes}")
            
        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        if img_state.pending_nodes:
            img_state.current_node = img_state.pending_nodes.pop(0)
        else:
            img_state.is_finished = True
            new_state.completed_images.add(current_idx)
        
        return new_state.dict()
    
    # å¤„ç†éæ ¹èŠ‚ç‚¹
    base_prompt = node_config.get("prompt", "")
    
    if base_prompt:
        # æ„å»ºå¢å¼ºpromptï¼ˆæ’é™¤å½“å‰èŠ‚ç‚¹ï¼‰
        history_for_context = img_state.node_history[:-1]
        
        enhanced_prompt = ContextBuilder.build_enhanced_prompt(
            node_history=history_for_context,
            base_prompt=base_prompt,
            node_name=img_state.current_node,
            context_type=context_type
        )
        
        # æ‰“å°ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        if context_type != "none" and history_for_context:
            print(f"ğŸ“‹ å›¾ç‰‡{current_idx+1} ä½¿ç”¨çš„ä¸Šä¸‹æ–‡ï¼š")
            for hist in history_for_context[-3:]:  # åªæ˜¾ç¤ºæœ€è¿‘3ä¸ª
                print(f"   - {hist.node_name}: {hist.node_result[:50]}...")
        
        result = call_qwen_vl_api(image_base64, enhanced_prompt)
        img_state.node_result = result
        current_history.node_result = result
        
        print(f"ğŸ“Œ å›¾ç‰‡{current_idx+1} èŠ‚ç‚¹{img_state.current_node}è¿”å›ï¼š{result}")
    else:
        # å¦‚æœæ²¡æœ‰promptï¼Œç›´æ¥ä½¿ç”¨ç©ºç»“æœ
        img_state.node_result = ""
        current_history.node_result = "æ— promptèŠ‚ç‚¹"
        print(f"ğŸ“Œ å›¾ç‰‡{current_idx+1} èŠ‚ç‚¹{img_state.current_node}ï¼ˆæ— promptï¼‰")
    
    # æ”¶é›†é£é™©å’Œå»ºè®®
    risk = node_config.get("risk", "").strip()
    rectify = node_config.get("rectify", "").strip()
    
    if risk and risk != "æ— " and risk not in img_state.risks:
        img_state.risks.append(risk)
        print(f"âœ… å›¾ç‰‡{current_idx+1} æ”¶é›†é£é™©ï¼š{risk[:50]}...")
    
    if rectify and rectify != "æ— " and rectify not in img_state.rectifies:
        img_state.rectifies.append(rectify)
        print(f"âœ… å›¾ç‰‡{current_idx+1} æ”¶é›†æ•´æ”¹å»ºè®®ï¼š{rectify[:50]}...")
    
    # å¤„ç†å­èŠ‚ç‚¹æ˜ å°„
    child_map = node_config.get("child_map", {})
    next_node = child_map.get(img_state.node_result.strip())
    
    if next_node and next_node not in img_state.visited_nodes:
        img_state.current_node = next_node
        print(f"ğŸ“Œ å›¾ç‰‡{current_idx+1} æ˜ å°„åˆ°å­èŠ‚ç‚¹ï¼š{next_node}")
    elif img_state.pending_nodes:
        img_state.current_node = img_state.pending_nodes.pop(0)
        print(f"ğŸ“Œ å›¾ç‰‡{current_idx+1} ä»é˜Ÿåˆ—å–ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼š{img_state.current_node}")
    else:
        img_state.is_finished = True
        new_state.completed_images.add(current_idx)
        print(f"ğŸ“Œ å›¾ç‰‡{current_idx+1} æ£€æŸ¥å®Œæˆ")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å›¾ç‰‡éƒ½å®Œæˆäº†
    if len(new_state.completed_images) >= new_state.total_images:
        print("ğŸ”š æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼Œå¼€å§‹èšåˆç»“æœ...")
        aggregate_results(new_state)
    
    return new_state.dict()

def aggregate_results(state: MultiImageState):
    """èšåˆæ‰€æœ‰å›¾ç‰‡çš„ç»“æœåˆ°final_results"""
    for idx, img_state in state.image_states.items():
        pic_num = idx + 1
        
        if pic_num not in state.final_results:
            state.final_results[pic_num] = {"risk": [], "rectify": []}
        
        # å»é‡æ·»åŠ é£é™©å’Œæ•´æ”¹å»ºè®®
        for risk in img_state.risks:
            if risk and risk not in state.final_results[pic_num]["risk"]:
                state.final_results[pic_num]["risk"].append(risk)
        
        for rectify in img_state.rectifies:
            if rectify and rectify not in state.final_results[pic_num]["rectify"]:
                state.final_results[pic_num]["rectify"].append(rectify)

# ===================== è·¯ç”±å‡½æ•° =====================
def multi_image_router(state: MultiImageState) -> Literal["process_node", "__end__"]:
    if len(state.completed_images) >= state.total_images:
        return "__end__"
    
    active_images = [
        idx for idx, img_state in state.image_states.items()
        if not img_state.is_finished and idx not in state.completed_images
    ]
    
    if active_images:
        current_idx = active_images[0]
        img_state = state.image_states[current_idx]
        
        if img_state.current_node and img_state.current_node in state.tree_config:
            return "process_node"
        
        if img_state.pending_nodes:
            img_state.current_node = img_state.pending_nodes.pop(0)
            return "process_node"
        
        img_state.is_finished = True
        state.completed_images.add(current_idx)
        return "process_node"
    
    return "__end__"

# ===================== æ„å»ºGraph =====================
def build_multi_image_graph(tree_config: Dict[str, Any]) -> CompiledStateGraph:
    graph = StateGraph(MultiImageState)
    graph.add_node("process_node", process_image_node)
    graph.add_edge(START, "process_node")
    graph.add_conditional_edges(
        "process_node",
        multi_image_router,
        {"process_node": "process_node", "__end__": END}
    )
    return graph.compile()

# ===================== æ ¼å¼åŒ–ç»“æœ =====================
def format_check_result(check_results: Dict[int, Dict[str, List[str]]]) -> str:
    if not check_results:
        return "âœ… æœªæ£€æµ‹åˆ°ä»»ä½•å›¾ç‰‡çš„æ£€æŸ¥ç»“æœ"
    
    final_output = "ğŸ“‹ æ–½å·¥ç°åœºç”¨ç”µå®‰å…¨æ£€æŸ¥ç»“æœï¼ˆæŒ‰å›¾ç‰‡ç¼–å·ï¼‰\n"
    final_output += "="*80 + "\n"
    
    for pic_num in sorted(check_results.keys()):
        res = check_results[pic_num]
        risks = res.get("risk", [])
        rectifies = res.get("rectify", [])
        
        final_output += f"ğŸ–¼ï¸  ç¬¬{pic_num}å¼ å›¾ç‰‡\n"
        
        if not risks:
            final_output += "   âœ… æœªå‘ç°å®‰å…¨é£é™©ï¼Œç¬¦åˆæ–½å·¥ç”¨ç”µå®‰å…¨è§„èŒƒè¦æ±‚\n"
        else:
            final_output += "   âš ï¸  å‘ç°å®‰å…¨é£é™©ï¼š\n"
            max_len = max(len(risks), len(rectifies))
            for idx in range(max_len):
                risk = risks[idx] if idx < len(risks) else "æœªçŸ¥é£é™©"
                rectify = rectifies[idx] if idx < len(rectifies) else "è¯·æ ¹æ®ç°åœºæƒ…å†µåˆ¶å®šæ•´æ”¹æªæ–½"
                final_output += f"      {idx+1}. é£é™©éšæ‚£ï¼š{risk}\n"
                final_output += f"         æ•´æ”¹å»ºè®®ï¼š{rectify}\n"
        
        final_output += "-"*80 + "\n"
    
    return final_output.strip()

# ===================== Agentæ ¸å¿ƒ =====================
class MultiImageTreeAgent:
    def __init__(self, config_path: str = "tree_check_config.json"):
        self.tree_config = self.load_config(config_path)
        self.graph = build_multi_image_graph(self.tree_config)
    
    def load_config(self, config_path: str) -> Dict[str, Any]:
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        
        # ä¸ºæ‰€æœ‰èŠ‚ç‚¹æ·»åŠ é»˜è®¤çš„contextå­—æ®µ
        for node_name, node_config in config.items():
            if "context" not in node_config:
                config[node_name]["context"] = "none"
        
        return config
    
    def run(self, image_paths: List[str], question: Optional[str] = None) -> str:
        if not image_paths:
            raise ValueError("âŒ è¯·è‡³å°‘æä¾›1å¼ å›¾ç‰‡")
        if len(image_paths) > 5:
            raise ValueError("âŒ æœ€å¤šæ”¯æŒ5å¼ å›¾ç‰‡")
        
        # å¤„ç†è‡ªå®šä¹‰é—®é¢˜
        if question and question.strip():
            # å°†æ‰€æœ‰å›¾ç‰‡è½¬æ¢ä¸ºBase64
            image_base64_list = [image_to_base64_with_prefix(path) for path in image_paths]
            
            # æ„å»ºæ˜ç¡®çš„prompt
            prompt = f"""è¯·æ ¹æ®ä¸Šä¼ çš„{len(image_base64_list)}å¼ å›¾ç‰‡ï¼Œç»¼åˆåˆ†æå¹¶å›ç­”é—®é¢˜ã€‚

é—®é¢˜ï¼š{question}

è¦æ±‚ï¼š
1. è¯·ä»”ç»†åˆ†ææ¯ä¸€å¼ å›¾ç‰‡çš„å†…å®¹
2. ç»“åˆæ‰€æœ‰å›¾ç‰‡è¿›è¡Œç»¼åˆåˆ¤æ–­
3. å¦‚æœå›¾ç‰‡é—´å­˜åœ¨å·®å¼‚æˆ–è”ç³»ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
4. ç»™å‡ºåŸºäºæ‰€æœ‰å›¾ç‰‡çš„å®Œæ•´ç­”æ¡ˆ

ç°åœ¨å¼€å§‹åˆ†æï¼š"""
            
            # è°ƒç”¨å¤šå›¾ç‰‡API
            answer = call_qwen_vl_with_multiple_images(image_base64_list, prompt)
            return answer
        
        # æ ‘å½¢æ£€æŸ¥
        image_base64_list = [image_to_base64_with_prefix(path) for path in image_paths]
        
        # åˆå§‹åŒ–æ¯å¼ å›¾ç‰‡çš„çŠ¶æ€
        image_states = {}
        for idx in range(len(image_paths)):
            image_states[idx] = SingleImageState(
                image_idx=idx,
                current_node="root",
                pending_nodes=[],
                visited_nodes=set(),
                risks=[],
                rectifies=[],
                is_finished=False
            )
        
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state = MultiImageState(
            all_images_base64=image_base64_list,
            tree_config=self.tree_config,
            image_states=image_states,
            completed_images=set(),
            total_images=len(image_paths),
            final_results={}
        )
        
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ ‘å½¢æ£€æŸ¥ï¼Œå…±{len(image_paths)}å¼ å›¾ç‰‡")
        
        try:
            final_state_dict = self.graph.invoke(initial_state)
            final_state = MultiImageState(**final_state_dict)
            
            print(f"âœ… æ£€æŸ¥å®Œæˆï¼Œå…±å¤„ç†{len(final_state.completed_images)}å¼ å›¾ç‰‡")
            
            return format_check_result(final_state.final_results)
            
        except Exception as e:
            print(f"âŒ æ‰§è¡ŒGraphå¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            return f"âŒ æ£€æŸ¥è¿‡ç¨‹å‡ºé”™ï¼š{str(e)}"

# ===================== Chainlité›†æˆ =====================
agent = None

@cl.on_chat_start
async def start_chat():
    global agent
    try:
        agent = MultiImageTreeAgent()
        await cl.Message(
            content="""ğŸ‰ æ¬¢è¿ä½¿ç”¨æ–½å·¥ç°åœºç”¨ç”µå®‰å…¨æ£€æŸ¥Agentï¼
âœ… ä½¿ç”¨æ–¹å¼1ï¼ˆè‡ªåŠ¨æ ‘å½¢æ£€æŸ¥ï¼‰ï¼šä¸Šä¼ 1~5å¼ å›¾ç‰‡ â†’ ç›´æ¥å‘é€ï¼ˆæ— éœ€è¾“å…¥æ–‡å­—ï¼‰
âœ… ä½¿ç”¨æ–¹å¼2ï¼ˆè‡ªå®šä¹‰æé—®ï¼‰ï¼šä¸Šä¼ å›¾ç‰‡åè¾“å…¥é—®é¢˜ â†’ å‘é€
âœ… æ”¯æŒæ ¼å¼ï¼šJPG/PNGï¼Œæœ€å¤š5å¼ å›¾ç‰‡
âœ… å¤šå›¾ç‰‡æé—®ï¼šä¸Šä¼ å¤šå¼ å›¾ç‰‡å¹¶æé—®ï¼Œç³»ç»Ÿä¼šç»¼åˆåˆ†ææ‰€æœ‰å›¾ç‰‡

ğŸ” æ”¯æŒæ™ºèƒ½ä¸Šä¸‹æ–‡ä¼ é€’ï¼šé€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶èŠ‚ç‚¹æ˜¯å¦éœ€è¦ä¸Šä¸‹æ–‡"""
        ).send()
    except Exception as e:
        await cl.Message(content=f"âŒ Agentåˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}").send()

@cl.on_message
async def handle_message(message: cl.Message):
    global agent
    try:
        if agent is None:
            agent = MultiImageTreeAgent()
        
        image_paths = []
        
        if hasattr(message, 'elements') and message.elements:
            for element in message.elements:
                is_image = False
                
                if hasattr(element, 'type') and element.type == 'image':
                    is_image = True
                elif hasattr(element, 'mime') and element.mime:
                    if isinstance(element.mime, str) and element.mime.startswith('image/'):
                        is_image = True
                elif hasattr(element, 'name') and element.name:
                    name = element.name.lower()
                    if any(name.endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):
                        is_image = True
                
                if is_image and hasattr(element, 'path') and element.path and os.path.exists(element.path):
                    image_paths.append(element.path)
        
        if not image_paths:
            await cl.Message(content="âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆå›¾ç‰‡ï¼è¯·ä¸Šä¼ å›¾ç‰‡ã€‚").send()
            return
        
        if len(image_paths) > 5:
            await cl.Message(content="âŒ æœ€å¤šæ”¯æŒ5å¼ å›¾ç‰‡").send()
            return
        
        user_question = message.content.strip() if message.content else ""
        
        if user_question:
            # å¤šå›¾ç‰‡è‡ªå®šä¹‰é—®é¢˜
            if len(image_paths) == 1:
                await cl.Message(content="ğŸ” æ­£åœ¨æ ¹æ®é—®é¢˜åˆ†æå›¾ç‰‡...").send()
            else:
                await cl.Message(content=f"ğŸ” æ­£åœ¨ç»¼åˆåˆ†æ{len(image_paths)}å¼ å›¾ç‰‡ï¼Œè¯·ç¨å€™...").send()
        else:
            # æ ‘å½¢æ£€æŸ¥
            await cl.Message(content=f"ğŸ” æ­£åœ¨æ™ºèƒ½æ£€æŸ¥{len(image_paths)}å¼ å›¾ç‰‡ï¼Œè¯·ç¨å€™...").send()
        
        result = agent.run(image_paths, user_question)
        
        await cl.Message(content=result).send()
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"âŒ å®Œæ•´é”™è¯¯ä¿¡æ¯:\n{error_detail}")
        await cl.Message(content=f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}").send()

# ===================== ä¸»ç¨‹åº =====================
if __name__ == "__main__":
    print("=" * 60)
    print("âœ… æ–½å·¥ç°åœºç”¨ç”µå®‰å…¨æ£€æŸ¥Agentåˆå§‹åŒ–å®Œæˆï¼")
    print("âœ… LangGraphç‰ˆæœ¬: 1.0.7")
    print("âœ… Chainlitç‰ˆæœ¬: 2.9.6")
    print("âœ… æ”¯æŒé…ç½®é©±åŠ¨çš„æ™ºèƒ½ä¸Šä¸‹æ–‡")
    print("âœ… æ”¯æŒå¤šå›¾ç‰‡ç»¼åˆåˆ†æï¼ˆè‡ªå®šä¹‰é—®é¢˜ï¼‰")
    print("âœ… æ‰§è¡Œå‘½ä»¤å¯åŠ¨: chainlit run æœ¬æ–‡ä»¶.py")
    print("=" * 60)