import os
import base64
import requests
from dotenv import load_dotenv
from PIL import Image
from langgraph.graph import StateGraph, MessagesState, START, END
import chainlit as cl


# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
if not DASHSCOPE_API_KEY:
    raise ValueError("âŒ è¯·é…ç½®DASHSCOPE_API_KEY")

DASHSCOPE_API_URL = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation"

# 2. è¾…åŠ©å‡½æ•°ï¼šå›¾ç‰‡è½¬å¸¦å‰ç¼€çš„Base64ï¼ˆå…¼å®¹æœ¬åœ°è·¯å¾„/Chainlitå›¾ç‰‡ï¼‰
def image_to_base64_with_prefix(image_path: str) -> str:
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨ï¼š{image_path}")
    
    try:
        with Image.open(image_path) as img:
            img_format = img.format.lower()
            if img_format == "jpg":
                img_format = "jpeg"
            if img_format not in ["jpeg", "png"]:
                raise ValueError(f"âŒ ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼š{img.format}ï¼Œä»…æ”¯æŒJPG/PNG")
    except Exception as e:
        raise ValueError(f"âŒ è¯†åˆ«å›¾ç‰‡æ ¼å¼å¤±è´¥ï¼š{str(e)}")
    
    with open(image_path, "rb") as f:
        base64_str = base64.b64encode(f.read()).decode("utf-8").strip()
    base64_with_prefix = f"data:image/{img_format};base64,{base64_str}"
    return base64_with_prefix

# 3. æ ¸å¿ƒï¼šè°ƒç”¨é˜¿é‡Œäº‘å¤šæ¨¡æ€API
def call_qwen_vl_api(image_base64_list: list, question: str) -> str:
    headers = {
        "Authorization": f"Bearer {DASHSCOPE_API_KEY}",
        "Content-Type": "application/json"
    }
    
    content = []
    for img_b64 in image_base64_list:
        content.append({"type": "image", "image": img_b64})
    content.append({"type": "text", "text": question})
    
    payload = {
        "model": "qwen-vl-plus",
        "input": {
            "messages": [{"role": "user", "content": content}]
        },
        "parameters": {"temperature": 0.5, "result_format": "message"}
    }

    try:
        response = requests.post(DASHSCOPE_API_URL, headers=headers, json=payload, timeout=30)
        response_json = response.json()
        response.raise_for_status()
        
        choices = response_json["output"]["choices"]
        if not choices:
            raise RuntimeError("âŒ æ— æœ‰æ•ˆå›å¤")
        content_list = choices[0]["message"]["content"]
        pure_text = content_list[0]["text"] if (isinstance(content_list, list) and len(content_list) > 0) else str(content_list)
        
        return pure_text
    
    except requests.exceptions.HTTPError as e:
        err_code = response_json.get("code", "æœªçŸ¥")
        err_msg = response_json.get("message", "æœªçŸ¥")
        raise RuntimeError(f"âŒ APIå¤±è´¥ï¼ˆçŠ¶æ€ç ï¼š{response.status_code}ï¼‰\né”™è¯¯ç ï¼š{err_code}\né”™è¯¯ä¿¡æ¯ï¼š{err_msg}")
    except Exception as e:
        raise RuntimeError(f"âŒ è°ƒç”¨å¼‚å¸¸ï¼š{str(e)}")

# 4. LangGraphèŠ‚ç‚¹å‡½æ•°
def multimodal_agent_node(state: MessagesState):
    try:
        user_msg = state["messages"][0]
        image_base64_list = []
        question = None
        
        for item in user_msg.content:
            if item["type"] == "image_base64":
                image_base64_list.append(item["image_base64"])
            elif item["type"] == "text":
                question = item["text"]
        
        if not image_base64_list:
            raise ValueError("âŒ æœªæ£€æµ‹åˆ°å›¾ç‰‡")
        if not question:
            raise ValueError("âŒ æœªæ£€æµ‹åˆ°é—®é¢˜")
        if len(image_base64_list) > 5:
            raise ValueError("âŒ æœ€å¤šæ”¯æŒ5å¼ å›¾ç‰‡")
        
        ai_answer = call_qwen_vl_api(image_base64_list, question)
        return {"messages": [{"role": "ai", "content": ai_answer}]}
    
    except Exception as e:
        print(f"âŒ èŠ‚ç‚¹å¤±è´¥ï¼š{str(e)}")
        raise

# 5. æ„å»ºLangGraphå·¥ä½œæµ
graph = StateGraph(MessagesState)
graph.add_node("multimodal_agent", multimodal_agent_node)
graph.add_edge(START, "multimodal_agent")
graph.add_edge("multimodal_agent", END)
compiled_graph = graph.compile()

# 6. Agentè°ƒç”¨å‡½æ•°
def run_agent(image_paths: list, question: str):
    if not image_paths or len(image_paths) == 0:
        raise ValueError("âŒ è¯·è‡³å°‘æä¾›1å¼ å›¾ç‰‡")
    if len(image_paths) > 5:
        raise ValueError("âŒ æœ€å¤šæ”¯æŒ5å¼ å›¾ç‰‡")

    image_base64_list = [image_to_base64_with_prefix(img_path) for img_path in image_paths]

    contents = []
    for b64 in image_base64_list:
        contents.append({"type": "image_base64", "image_base64": b64})
    contents.append({"type": "text", "text": question})

    user_message = {"role": "user", "content": contents}
    result = compiled_graph.invoke({"messages": [user_message]})

    ai_msg = result["messages"][-1]
    final_answer = ai_msg.content if hasattr(ai_msg, "content") else (ai_msg["content"] if isinstance(ai_msg, dict) else str(ai_msg))

    return final_answer

# 7. Chainlitæ ¸å¿ƒäº¤äº’é€»è¾‘
@cl.on_chat_start
async def start_chat():
    """åˆå§‹åŒ–ï¼šæ˜ç¡®æç¤ºä¸Šä¼ æ–¹å¼"""
    await cl.Message(
        content="""ğŸ‰ æ¬¢è¿ä½¿ç”¨æ–½å·¥ç°åœºæ£€æŸ¥Agentï¼
âœ… ä¸Šä¼ å›¾ç‰‡æ–¹å¼ï¼šç‚¹å‡»è¾“å…¥æ¡†å·¦ä¾§ã€ŒğŸ“ã€å›¾æ ‡ â†’ é€‰æ‹©ã€ŒImagesã€â†’ ä¸Šä¼ 1~5å¼ JPG/PNGå›¾ç‰‡
âœ… è¾“å…¥é—®é¢˜åå‘é€ï¼Œå³å¯åˆ†ææ‰€æœ‰å›¾ç‰‡çš„ä¾›ç”µç®±/æ‚ç‰©å †æ”¾æƒ…å†µ"""
    ).send()

@cl.on_message
async def handle_message(message: cl.Message):
    """å¤„ç†æ¶ˆæ¯ï¼šé€‚é…Chainlit v1.x å›¾ç‰‡å…ƒç´ """
    try:
        # ========== æ ¸å¿ƒä¿®æ­£ï¼šChainlit v1.x å›¾ç‰‡å…ƒç´ è¯†åˆ« ==========
        # æ­¥éª¤1ï¼šæ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆæ–¹ä¾¿æ’æŸ¥ï¼‰
        #await cl.Message(content=f"ğŸ” è°ƒè¯•ï¼šæ”¶åˆ°çš„å…ƒç´ æ€»æ•°={len(message.elements)}ï¼Œå…ƒç´ è¯¦æƒ…={[{'type': type(e), 'name': getattr(e, 'name', 'æ— '), 'mime': getattr(e, 'mime_type', 'æ— ')} for e in message.elements]}").send()
        
        # æ­¥éª¤2ï¼šç­›é€‰å›¾ç‰‡å…ƒç´ ï¼ˆv1.x ä¼˜å…ˆè¯†åˆ« cl.Image ç±»å‹ï¼‰
        image_elements = []
        # å…¼å®¹ä¸¤ç§æƒ…å†µï¼šcl.Image ç±»å‹ / Fileç±»å‹ï¼ˆå…œåº•ï¼‰
        for elem in message.elements:
            # æƒ…å†µ1ï¼šChainlit v1.x ä¸Šä¼ å›¾ç‰‡çš„åŸç”Ÿç±»å‹ï¼ˆæ ¸å¿ƒï¼‰
            if isinstance(elem, cl.Image):
                image_elements.append(elem)
            # æƒ…å†µ2ï¼šå…œåº•å…¼å®¹ File ç±»å‹
            elif isinstance(elem, cl.File) and getattr(elem, 'mime_type', '').startswith('image/'):
                image_elements.append(elem)
        
        # æ­¥éª¤3ï¼šæ ¡éªŒå›¾ç‰‡æ•°é‡
        if not image_elements:
            await cl.Message(
                content="""âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆå›¾ç‰‡ï¼è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
1. ç‚¹å‡»è¾“å…¥æ¡†å·¦ä¾§çš„ã€ŒğŸ“ã€å›¾æ ‡ï¼ˆé™„ä»¶å›¾æ ‡ï¼‰ï¼›
2. é€‰æ‹©ã€ŒImagesã€é€‰é¡¹ï¼ˆè€Œéã€ŒFilesã€ï¼‰ï¼›
3. ä¸Šä¼ 1~5å¼ JPG/PNGæ ¼å¼çš„æ–½å·¥ç°åœºå›¾ç‰‡ï¼›
4. è¾“å…¥é—®é¢˜åé‡æ–°å‘é€ã€‚"""
            ).send()
            return
        
        if len(image_elements) > 5:
            await cl.Message(content=f"âŒ ä¸Šä¼ äº†{len(image_elements)}å¼ å›¾ç‰‡ï¼Œæœ€å¤šä»…æ”¯æŒ5å¼ ï¼è¯·é‡æ–°ä¸Šä¼ ã€‚").send()
            return
        
        # æ­¥éª¤4ï¼šæå–æ‰€æœ‰å›¾ç‰‡çš„æœ¬åœ°è·¯å¾„ï¼ˆv1.x å›¾ç‰‡å…ƒç´ çš„ path å±æ€§ï¼‰
        image_paths = []
        for img_elem in image_elements:
            # cl.Image å’Œ cl.File éƒ½æœ‰ path å±æ€§
            if hasattr(img_elem, 'path') and os.path.exists(img_elem.path):
                image_paths.append(img_elem.path)
            else:
                await cl.Message(content=f"âŒ å›¾ç‰‡{getattr(img_elem, 'name', 'æœªçŸ¥')}è·¯å¾„æ— æ•ˆï¼").send()
                return
        
        # æ­¥éª¤5ï¼šè°ƒç”¨Agentå¹¶è¿”å›ç»“æœ
        answer = run_agent(image_paths, message.content)
        await cl.Message(content=f"âœ… å·²åˆ†æ{len(image_elements)}å¼ å›¾ç‰‡ï¼Œæ£€æŸ¥ç»“æœï¼š\n\n{answer}").send()
    
    except Exception as e:
        await cl.Message(content=f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}\nğŸ” é”™è¯¯è¯¦æƒ…ï¼š{e.__traceback__}").send()